apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kube-prometheus-stack
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://prometheus-community.github.io/helm-charts
    targetRevision: 56.6.2
    chart: kube-prometheus-stack
    helm:
      values: |
        prometheus:
          prometheusSpec:
            retention: 15d
            storageSpec:
              volumeClaimTemplate:
                spec:
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: 50Gi
                  storageClassName: gp3
            additionalScrapeConfigs:
              - job_name: 'yace-cloudwatch'
                static_configs:
                  - targets: ['yace-exporter:5000']
              - job_name: 'nginx-ingress-controller'
                kubernetes_sd_configs:
                  - role: pod
                    namespaces:
                      names:
                        - ingress-nginx
                relabel_configs:
                  - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_component]
                    action: keep
                    regex: controller
                  - source_labels: [__meta_kubernetes_pod_container_port_number]
                    action: keep
                    regex: "10254"
                  - source_labels: [__meta_kubernetes_namespace]
                    target_label: namespace
                  - source_labels: [__meta_kubernetes_pod_name]
                    target_label: pod

        grafana:
          enabled: true
          adminPassword: changeme

          ingress:
            enabled: true
            ingressClassName: nginx
            hosts:
              - grafana-dev.nymbl.host

          persistence:
            enabled: true
            storageClassName: gp3
            size: 10Gi

          # Enable the kube-prometheus-stack default dashboards
          defaultDashboardsEnabled: true
          defaultDashboardsTimezone: UTC

          #################################################################
          # 1) Dashboard providers â†’ tell Grafana where to look on disk
          #################################################################
          dashboardProviders:
            dashboardproviders.yaml:
              apiVersion: 1
              providers:
                # dotdc Kubernetes dashboards (15757, 15761, etc.)
                - name: grafana-dashboards-kubernetes
                  orgId: 1
                  folder: Kubernetes
                  type: file
                  disableDeletion: true
                  editable: true
                  options:
                    path: /var/lib/grafana/dashboards/grafana-dashboards-kubernetes

                # Your extra community dashboards
                - name: custom
                  orgId: 1
                  folder: Custom
                  type: file
                  disableDeletion: true
                  editable: true
                  options:
                    path: /var/lib/grafana/dashboards/custom

          #################################################################
          # 2) Dashboards from URLs and grafana.com IDs
          #################################################################
          dashboards:
            # dotdc Kubernetes views set (uses raw GitHub URLs)
            grafana-dashboards-kubernetes:
              k8s-views-global:
                # 15757 - Kubernetes / Views / Global
                url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-global.json
                token: ""
              k8s-system-api-server:
                # 15761 - Kubernetes / System / API Server
                url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-system-api-server.json
                token: ""
              k8s-views-namespaces:
                # 15758 - Kubernetes / Views / Namespaces
                url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-namespaces.json
                token: ""
              k8s-views-nodes:
                # 15759 - Kubernetes / Views / Nodes
                url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-nodes.json
                token: ""
              k8s-views-pods:
                # 15760 - Kubernetes / Views / Pods
                url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-pods.json
                token: ""

            # Your extra dashboards by ID
            custom:
              k8s-cluster-monitoring-14584:
                gnetId: 14584
                datasource: Prometheus
              nginx-ingress-14314:
                gnetId: 14314
                datasource: Prometheus

            # AWS Services dashboards via YACE
            # Note: These community dashboards are NOT compatible with YACE
            # Use ConfigMaps with custom dashboards instead (see aws-dashboards-configmap.yaml)

          #################################################################
          # 3) Set 15757 as the home dashboard
          #################################################################
          grafana.ini:
            dashboards:
              # This file is created by the Helm chart when it downloads
              # the URL above into /var/lib/grafana/dashboards/...
              default_home_dashboard_path: /var/lib/grafana/dashboards/grafana-dashboards-kubernetes/k8s-views-global.json

          #################################################################
          # 4) Sidecar for ConfigMap dashboards (optional, for future use)
          #################################################################
          sidecar:
            dashboards:
              enabled: true
              label: grafana_dashboard
              labelValue: "1"
              searchNamespace: ALL
              folder: /tmp/dashboards
              provider:
                foldersFromFilesStructure: true

        alertmanager:
          enabled: true
          config:
            global:
              resolve_timeout: 5m
            route:
              group_by: ['alertname', 'cluster', 'service']
              group_wait: 10s
              group_interval: 10s
              repeat_interval: 12h
              receiver: 'sns-forwarder'
            receivers:
              - name: 'sns-forwarder'
                webhook_configs:
                  - url: 'http://alertmanager-sns-forwarder:9087/alert'

  destination:
    server: https://kubernetes.default.svc
    namespace: monitoring

  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
